{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Attention.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rnhondova/attention-learn-to-route/blob/master/Attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHWBoJA3KA53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4693ecb7-60ef-4f05-d08c-7997d9dc723e"
      },
      "source": [
        "# This ensures that a gpu is being used by the current google colab session.\n",
        "\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Mar 26 14:54:01 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.56       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycwxgcUMAWQQ",
        "outputId": "e3de0677-dbec-415d-d5fb-a94b3e104bdc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLd2Yfk653Gu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f76d9183-0615-449f-bf09-168fca6f709a"
      },
      "source": [
        "# This code block is used to access your google drive\n",
        "\n",
        "from google.colab import drive\n",
        "ROOT = \"/content/drive\"\n",
        "drive.mount(ROOT)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xO6Ir-cHwqnv",
        "outputId": "fa206c5a-fbec-4d0c-8dcc-ee657faa845f"
      },
      "source": [
        "!git clone https://github.com/Rnhondova/garage.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'garage'...\n",
            "remote: Enumerating objects: 4, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 25262 (delta 0), reused 2 (delta 0), pack-reused 25258\u001b[K\n",
            "Receiving objects: 100% (25262/25262), 58.58 MiB | 20.47 MiB/s, done.\n",
            "Resolving deltas: 100% (18783/18783), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFov2CnGyviD",
        "outputId": "c1295d1e-e887-4e68-ef13-860615fd828d"
      },
      "source": [
        "!git submodule update --init --recursive"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Submodule 'src/attention-learn-to-route' (https://github.com/Rnhondova/attention-learn-to-route.git) registered for path './'\n",
            "Submodule 'src/garage/torch/algos/attention-learn-to-route' (https://github.com/Rnhondova/attention-learn-to-route.git) registered for path '../garage/torch/algos/attention-learn-to-route'\n",
            "Cloning into '/content/garage/src/attention-learn-to-route'...\n",
            "Cloning into '/content/garage/src/garage/torch/algos/attention-learn-to-route'...\n",
            "Submodule path './': checked out 'b1b1b0cd3ff857ad92472e1f6da3e9b21d96f015'\n",
            "Submodule path '../garage/torch/algos/attention-learn-to-route': checked out 'ffd5b862f5b12867d82cfa9ea78344cc0d1bb4b8'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnXWqHp0w-y3",
        "outputId": "627b9e54-e4b9-42e8-8bb2-6222d37671f8"
      },
      "source": [
        "#%cd garage/src/garage/torch/algos/attention-learn-to-route/\n",
        "%cd garage/src/attention-learn-to-route/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/garage/src/attention-learn-to-route\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTNHf8woxkr9",
        "outputId": "a937facd-68c2-4204-cf9f-933c358d2666"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "environment.yml\t\t nets\t\t reinforce_baselines.py\n",
            "eval.py\t\t\t options.py\t run.py\n",
            "garage_requirements.txt  outputs\t simple_tsp.ipynb\n",
            "generate_data.py\t plot_vrp.ipynb  train_copy.py\n",
            "images\t\t\t pretrained\t train.py\n",
            "LICENSE\t\t\t problems\t TRPO_Attention.py\n",
            "logs\t\t\t __pycache__\t utils\n",
            "Makefile\t\t README.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqFZroDoBh7T"
      },
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install -r garage_requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGZLM66tz6lS",
        "outputId": "80eb4c9d-d5c5-47f7-de4c-a9f01477af08"
      },
      "source": [
        "!python run.py --graph_size 20 --batch_size 512 --problem cvrp --baseline rollout --run_name 'vrp100_rollout' --epoch_size 12800 --n_epochs 1"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-03-26 16:12:21.728155: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "{'baseline': 'rollout',\n",
            " 'batch_size': 512,\n",
            " 'bl_alpha': 0.05,\n",
            " 'bl_warmup_epochs': 1,\n",
            " 'checkpoint_encoder': False,\n",
            " 'checkpoint_epochs': 1,\n",
            " 'data_distribution': None,\n",
            " 'embedding_dim': 128,\n",
            " 'epoch_size': 12800,\n",
            " 'epoch_start': 0,\n",
            " 'eval_batch_size': 1024,\n",
            " 'eval_only': False,\n",
            " 'exp_beta': 0.8,\n",
            " 'graph_size': 20,\n",
            " 'hidden_dim': 128,\n",
            " 'load_path': None,\n",
            " 'log_dir': 'logs',\n",
            " 'log_step': 50,\n",
            " 'lr_critic': 0.0001,\n",
            " 'lr_decay': 1.0,\n",
            " 'lr_model': 0.0001,\n",
            " 'max_grad_norm': 1.0,\n",
            " 'model': 'attention',\n",
            " 'n_encode_layers': 3,\n",
            " 'n_epochs': 1,\n",
            " 'no_cuda': False,\n",
            " 'no_progress_bar': False,\n",
            " 'no_tensorboard': False,\n",
            " 'normalization': 'batch',\n",
            " 'output_dir': 'outputs',\n",
            " 'problem': 'cvrp',\n",
            " 'resume': None,\n",
            " 'run_name': 'vrp100_rollout_20210326T161223',\n",
            " 'save_dir': 'outputs/cvrp_20/vrp100_rollout_20210326T161223',\n",
            " 'seed': 1234,\n",
            " 'shrink_size': None,\n",
            " 'tanh_clipping': 10.0,\n",
            " 'use_cuda': True,\n",
            " 'val_dataset': None,\n",
            " 'val_size': 10000}\n",
            "Evaluating baseline model on evaluation dataset\n",
            "100% 10/10 [00:00<00:00, 11.04it/s]\n",
            "Start train epoch 0, lr=0.0001 for run vrp100_rollout_20210326T161223\n",
            "  0% 0/25 [00:00<?, ?it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"run.py\", line 172, in <module>\n",
            "    run(get_options())\n",
            "  File \"run.py\", line 167, in run\n",
            "    opts\n",
            "  File \"/content/garage/src/attention-learn-to-route/train_copy.py\", line 102, in train_epoch\n",
            "    opts\n",
            "  File \"/content/garage/src/attention-learn-to-route/train_copy.py\", line 182, in train_batch\n",
            "    print('VPG run' + str(vpg._train_once(1, eps)))\n",
            "  File \"/content/garage/src/garage/torch/algos/vpg.py\", line 147, in _train_once\n",
            "    obs = torch.Tensor(eps.padded_observations)\n",
            "TypeError: new(): data must be a sequence (got dict)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwHxwKkL6qh3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6280537-3c16-4b25-8a6e-695f3c73292c"
      },
      "source": [
        "# Make sure this points to the project folder\n",
        "\n",
        "%cd drive/'My Drive'/CORL"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/CORL\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQXpBJPg0-V1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9d1f5ed-e87f-410e-e8b9-eba737d090c6"
      },
      "source": [
        "%cd attention"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/CORL/attention\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pplMLCu-M8m"
      },
      "source": [
        "%%capture\n",
        "!pip install wandb --upgrade\n",
        "!pip install tensorboard_logger"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "id": "DJVJJzi9Wrzb",
        "outputId": "af67a606-70e8-4078-84bc-3864565067db"
      },
      "source": [
        "import wandb\n",
        "\n",
        "wandb.login()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Paste an API key from your profile and hit enter: ··········\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cgIK0U5M26a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40f1ba7a-aba6-4c30-b2fb-1192a4c9a5e0"
      },
      "source": [
        "# This block will run the originial attention code with the below settings\n",
        "# The save_hrs are the checkpoint hours to save the model\n",
        "\n",
        "!python run.py --graph_size 100 --batch_size 64 --problem cvrp --baseline rollout --run_name 'vrp100_rollout' --save_hrs 5 10 --epoch_size 12800 --n_epochs 500\n",
        "\n",
        "# this is an example of how to run evolution code\n",
        "#!python vrp_evolve.py --save_dir ../models/att_evo --save_hrs 2 3 4 5 6 8 10 --sigma 0.001 --lr 0.000001 --dataset_size 12800 --epochs 500"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-01-26 13:50:45.455415: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrnhondova\u001b[0m (use `wandb login --relogin` to force relogin)\n",
            "2021-01-26 13:50:59.439484: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.15\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33meternal-haze-2\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/rnhondova/pytorch-attention-model\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/rnhondova/pytorch-attention-model/runs/25jujl2f\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in /content/drive/My Drive/CORL/attention/wandb/run-20210126_135052-25jujl2f\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb offline` to turn off syncing.\n",
            "\n",
            "{'baseline': 'rollout',\n",
            " 'batch_size': 64,\n",
            " 'bl_alpha': 0.05,\n",
            " 'bl_warmup_epochs': 1,\n",
            " 'checkpoint_encoder': False,\n",
            " 'checkpoint_epochs': 1,\n",
            " 'data_distribution': None,\n",
            " 'embedding_dim': 128,\n",
            " 'epoch_size': 12800,\n",
            " 'epoch_start': 0,\n",
            " 'eval_batch_size': 1024,\n",
            " 'eval_only': False,\n",
            " 'exp_beta': 0.8,\n",
            " 'graph_size': 100,\n",
            " 'hidden_dim': 128,\n",
            " 'load_path': None,\n",
            " 'log_dir': 'logs',\n",
            " 'log_step': 50,\n",
            " 'lr_critic': 0.0001,\n",
            " 'lr_decay': 1.0,\n",
            " 'lr_model': 0.0001,\n",
            " 'max_grad_norm': 1.0,\n",
            " 'model': 'attention',\n",
            " 'n_encode_layers': 3,\n",
            " 'n_epochs': 500,\n",
            " 'no_cuda': False,\n",
            " 'no_progress_bar': False,\n",
            " 'no_tensorboard': False,\n",
            " 'normalization': 'batch',\n",
            " 'output_dir': 'outputs',\n",
            " 'problem': 'cvrp',\n",
            " 'resume': None,\n",
            " 'run_name': 'vrp100_rollout_20210126T135052',\n",
            " 'save_dir': 'outputs/cvrp_100/vrp100_rollout_20210126T135052',\n",
            " 'save_hrs': [5, 10],\n",
            " 'seed': 1234,\n",
            " 'shrink_size': None,\n",
            " 'tanh_clipping': 10.0,\n",
            " 'use_cuda': True,\n",
            " 'val_dataset': None,\n",
            " 'val_size': 10000}\n",
            "Evaluating baseline model on evaluation dataset\n",
            "100%|██████████| 10/10 [00:09<00:00,  1.10it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"run.py\", line 210, in <module>\n",
            "    run(config)\n",
            "  File \"run.py\", line 167, in run\n",
            "    torch.save(model, os.path.join('.', 'empty.pt'))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/serialization.py\", line 372, in save\n",
            "    _save(obj, opened_zipfile, pickle_module, pickle_protocol)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/serialization.py\", line 476, in _save\n",
            "    pickler.dump(obj)\n",
            "AttributeError: Can't pickle local object 'TorchGraph.hook_torch_modules.<locals>.backward_hook'\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 372\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Program failed with code 1.  Press ctrl-c to abort syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: /content/drive/My Drive/CORL/attention/wandb/run-20210126_135052-25jujl2f/logs/debug.log\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: /content/drive/My Drive/CORL/attention/wandb/run-20210126_135052-25jujl2f/logs/debug-internal.log\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33meternal-haze-2\u001b[0m: \u001b[34mhttps://wandb.ai/rnhondova/pytorch-attention-model/runs/25jujl2f\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEU7zEhHUqzV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db68e877-7905-4546-f639-53e8a1d29f85"
      },
      "source": [
        "!git status"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31mHEAD detached at \u001b[mb1b1b0c\n",
            "Changes not staged for commit:\n",
            "  (use \"git add/rm <file>...\" to update what will be committed)\n",
            "  (use \"git checkout -- <file>...\" to discard changes in working directory)\n",
            "\n",
            "\t\u001b[31mmodified:   run.py\u001b[m\n",
            "\t\u001b[31mdeleted:    train copy.py\u001b[m\n",
            "\n",
            "Untracked files:\n",
            "  (use \"git add <file>...\" to include in what will be committed)\n",
            "\n",
            "\t\u001b[31mMakefile\u001b[m\n",
            "\t\u001b[31mgarage_requirements.txt\u001b[m\n",
            "\t\u001b[31mtrain_copy.py\u001b[m\n",
            "\n",
            "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_IWMkKGVbyp"
      },
      "source": [
        "!git add -A"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFZpTaAQVwLR"
      },
      "source": [
        "!git config --global user.email \"rnhondova@yahoo.com\""
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFFHnmrXV5xd"
      },
      "source": [
        "!git config --global user.name \"Ronald Nhondova\""
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQhvqoQIVfQ1",
        "outputId": "c0749741-6613-4824-c1f7-2a9212483c4d"
      },
      "source": [
        "!git commit -m \"Add required files to set garage\""
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[detached HEAD 18b3b07] Add required files to set garage\n",
            " 4 files changed, 53 insertions(+), 16 deletions(-)\n",
            " create mode 100644 Makefile\n",
            " create mode 100644 garage_requirements.txt\n",
            " rename train copy.py => train_copy.py (87%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Plx8L2EGV_vk",
        "outputId": "f0644d70-a0d8-4155-b7df-063c70c00ca2"
      },
      "source": [
        "!git push origin HEAD:master"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: could not read Username for 'https://github.com': No such device or address\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}